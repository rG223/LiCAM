# -*- coding: utf-8 -*-
# Copyright (c) Facebook, Inc. and its affiliates. All Rights Reserved

import logging
import numpy as np
import time
import weakref
import torch
from detectron2.utils.events import get_event_storage
import detectron2.utils.comm as comm
from detectron2.utils.events import EventStorage

__all__ = ["HookBase", "TrainerBase", "SimpleTrainer"]
bili = [0.10561221155608518,0.010649149916386018,0.003094551360111098,0.07285905733932459,0.055612227341126974,0.29517259127213546,0.0067716065056548725,0.4604692423845314,0.7194831912258303,0.29517259127213546,0.011308183752075917,0.0006596602521123881,1.6445330085161836,0.18567308160666587,0.013066664085826655,0.31977030721148014,1.4389663824516605,0.13543213011309746,0.010352276132745761,1.0465210054193894,0.5005100460701428,0.03928918450379961,0.004229144401033535,0.08464508132068592,0.011880011413429602,0.17181688148676544,0.010984476201921074,0.07062411693014285,0.002695955751665875,1.4389663824516605,3.8372436865377613,0.025753313332468195,0.27408883475269724,0.0029464374352734285,0.002916577415660827,0.0013484515707641192,0.030945513601110985,1.9186218432688806,1.2790812288459206,11.511731059613284,0.015247325906772562,0.9593109216344403,0.007398284742682059,0.04737337884614521,0.0002277205859236684,0.6058805820849097,0.1251275115175357,0.05256498200736659,3.8372436865377613,0.0019488286879318242,2.877932764903321,3.8372436865377613,0.016282505034813696,0.09673723579506961,0.3837243686537762,0.028494383810923972,0.011363999071681426,0.0042667646625697865,0.0012751142068689945,0.004539326127607762,0.002889490727814579,0.20556662606452294,1.9186218432688806,0.2449304480768784,0.034261104344087155,0.009513827321994451,0.21720247282289215,0.013262362971904706,0.44275888690820325,0.07426923264266636,3.8372436865377613,0.008396594500082628,0.0498343335913995,0.5755865529806643,0.006036565841433291,0.010768691356046103,0.0053868652595289125,5.755865529806642,0.0612326120192196,0.0014238381026114143,0.009268704556854496,2.877932764903321,0.009382013903515308,0.05670803477642012,1.2790812288459206,0.019511408575615737,0.002634866344612791,0.0031256397120861482,0.01954453490596483,0.0026318543803414,0.20196019402830323,0.11991386520430504,5.755865529806642,0.002521185076568831,0.014815612689334985,0.011230957131330033,0.0370152124103321,0.5232605027096947,0.000996082985170311,0.7194831912258303,0.9593109216344403,0.06395406144229603,0.1918621843268881,0.0370152124103321,0.5005100460701428,11.511731059613284,0.053793135792585434,0.02835401738821006,0.07475150038709925,0.0037436523771100113,0.09283654080333294,0.036429528669662294,3.8372436865377613,0.009071498076921421,0.018477898972091948,0.005445473538133058,0.6771606505654874,0.0011533644985084945,5.755865529806642,0.06058805820849097,0.2677146758049601,0.09209384847690628,11.511731059613284,0.2502550230350714,0.0010222654346517435,1.1511731059613286,0.00034514829429476465,0.101873726191268,0.026222622003674905,0.7674487373075524,1.1511731059613286,0.0027448095039612026,0.0014445640682159977,0.7674487373075524,0.21720247282289215,1.9186218432688806,0.010062701975186437,0.032066103230120574,0.0021687511416000915,11.511731059613284,0.12934529280464363,0.30294029104245485,0.0014655290973409655,0.5232605027096947,0.13081512567742368,0.003576182373287755,2.877932764903321,0.09755704287807868,0.6771606505654874,0.0017575161923073716,3.8372436865377613,0.09755704287807868,0.13704441737634862,0.0009462215238873323,1.2790812288459206,0.07994257680287004,0.05304945188761882,0.019511408575615737,2.877932764903321,0.008552549078464549,0.6058805820849097,0.05005100460701428,0.5481776695053945,2.877932764903321,0.14389663824516608,0.15147014552122742,0.4263604096153068,0.7674487373075524,0.006467264640232183,0.26163025135484735,0.008199238646448209,0.8222665042580918,0.0035086044070750636,0.13704441737634862,0.03737575019354963,0.03889098330950434,0.0014601383890935165,0.027806113670563487,0.5755865529806643,0.8222665042580918,0.0015617597421806113,0.12117611641698194,0.0050116373790218905,0.1918621843268881,0.04586347035702504,0.03824495368642287,0.2558162457691841,0.3385803252827437,0.004658733735173324,0.06893252131504961,0.11286010842758122,0.008084080800290227,0.5232605027096947,0.00268463877323071,0.021720247282289214,0.39695624343494085,0.10758627158517087,0.10860123641144608,0.05280610577804259,0.11991386520430504,0.05964627492027609,5.755865529806642,0.018100206068574348,0.0021748972340096895,0.4263604096153068,0.13231874781164693,0.001093439500343207,0.012404882607341901,1.1511731059613286,11.511731059613284,0.7194831912258303,0.09435845130830561,0.5232605027096947,0.7674487373075524,0.5232605027096947,0.23493328693088333,0.0006378043691957053,0.0498343335913995,0.22572021685516244,0.05588218960977322,0.3488403351397965,0.9593109216344403,0.15556393323801737,0.7674487373075524,0.004822677444328983,0.011122445468225394,0.23493328693088333,0.31112786647603474,0.012636367793208876,0.003966826691803337,0.8855177738164065,0.0009967729725182512,0.7674487373075524,11.511731059613284,0.029366660866360417,0.6058805820849097,5.755865529806642,3.8372436865377613,0.012748317895474289,0.8855177738164065,0.027606069687322023,0.04344049456457843,0.0325190142926929,5.755865529806642,0.2807739282832508,0.021278615636993133,0.5481776695053945,0.06431134670175019,0.14389663824516608,1.6445330085161836,11.511731059613284,0.008341834101169046,0.013704441737634864,0.020667380717438573,0.03799251174789863,0.10860123641144608,0.30294029104245485,3.8372436865377613,0.042794539255067966,0.3289066017032367,0.012776616048405421,11.511731059613284,0.05843518304372225,0.1827258898351315,1.4389663824516605,0.1065901024038267,0.03824495368642287,0.31977030721148014,11.511731059613284,11.511731059613284,0.004300235733886173,0.012351642767825412,0.2449304480768784,0.1037092888253449,11.511731059613284,0.029517259127213553,0.0027772571917040493,0.0408217413461464,0.7194831912258303,0.08721008378494913,11.511731059613284,2.877932764903321,0.0421675130388765,0.04247871239709699,0.016236574132035664,0.35974159561291513,1.6445330085161836,0.03774338052332224,0.7194831912258303,0.15988515360574007,11.511731059613284,0.8855177738164065,0.28779327649033215,0.11867763978982766,11.511731059613284,0.004193708947035805,0.0038565263181284037,0.002820811335362236,0.006485482287106076,2.877932764903321,2.302346211922657,11.511731059613284,0.005995693260215253,0.6395406144229603,0.023069601321870307,0.035312058465071426,1.6445330085161836,0.7674487373075524,0.006113505607866853,1.1511731059613286,0.1771035547632813,0.07725993999740459,11.511731059613284,0.9593109216344403,0.09283654080333294,1.9186218432688806,0.9593109216344403,0.39695624343494085,0.021517254317034176,0.2302346211922657,2.302346211922657,0.022572021685516242,0.9593109216344403,0.006283695993238692,0.19511408575615735,1.1511731059613286,0.07573507276061371,0.28779327649033215,0.08993539890322878,0.0016466501301120417,0.08222665042580918,0.47965546081722016,11.511731059613284,0.09136294491756575,0.11628011171326551,0.3289066017032367,0.13385733790248006,0.003810569698647231,0.5755865529806643,0.20930420108387787,0.060908629945043834,0.007509283143909513,0.6771606505654874,0.0024825816389073287,0.14389663824516608,0.007092871878997711,0.007071087874455334,0.5755865529806643,5.755865529806642,0.0025547561162035694,0.0016046460913874108,3.8372436865377613,0.47965546081722016,11.511731059613284,3.8372436865377613,1.0465210054193894,0.11176437921954643,0.006441931202917339,0.08855177738164065,0.5755865529806643,0.006926432647180076,1.0465210054193894,0.12934529280464363,5.755865529806642,0.4604692423845314,0.7674487373075524,0.03689657390901693,1.1511731059613286,0.021638592217318203,0.07524007228505414,0.35974159561291513,0.05162211237494746,0.036314609020862094,1.2790812288459206,0.01887169026166112,5.755865529806642,0.03270378141935592,0.0042890205140138915,0.01570495369660748,0.028923947385963027,5.755865529806642,5.755865529806642,0.30294029104245485,0.23493328693088333,0.002827045938018979,0.14758629563606773,0.0009664789740251266,5.755865529806642,1.4389663824516605,0.0014522178705201568,0.5005100460701428,0.004050573912601437,0.15147014552122742,0.03762003614252707,0.07573507276061371,0.47965546081722016,5.755865529806642,11.511731059613284,0.19511408575615735,0.4604692423845314,0.010561221155608517,0.31977030721148014,0.1495030007741985,0.017284881470890818,0.8855177738164065,0.12117611641698194,1.6445330085161836,0.23982773040861008,0.01500877582739672,0.29517259127213546,0.0037497495308186596,0.2677146758049601,0.29517259127213546,11.511731059613284,0.014159570799032331,0.7674487373075524,0.12790812288459205,0.22137944345410163,0.034159439346033486,11.511731059613284,0.006763649271218145,0.0021618274290353587,0.39695624343494085,0.05481776695053946,0.2807739282832508,2.302346211922657,1.2790812288459206,3.8372436865377613,0.015619716498796857,0.0036143582604751287,0.8222665042580918,2.302346211922657,0.35974159561291513,0.6771606505654874,0.07831109564362779,0.10010200921402856,0.010901260473118641,0.21720247282289215,3.8372436865377613,0.07623662953386282,0.06431134670175019,0.0697680670279593,0.17181688148676544,0.021720247282289214,0.0078955631410242,5.755865529806642,0.02192710678021578,0.11991386520430504,0.3488403351397965,0.13704441737634862,0.0016428901183977856,0.010639307818496566,0.037254793073182156,0.6395406144229603,0.05280610577804259,1.1511731059613286,0.23982773040861008,5.755865529806642,0.010436746200918662,0.23493328693088333,0.0029070027928316377,0.13385733790248006,0.3837243686537762,0.03799251174789863,0.5232605027096947,0.3289066017032367,1.6445330085161836,0.2807739282832508,0.0036696624353246042,0.8222665042580918,0.0951382732199445,0.2807739282832508,0.29517259127213546,0.004936419836883912,0.13704441737634862,0.31112786647603474,0.03713461632133318,2.877932764903321,1.2790812288459206,1.0465210054193894,2.877932764903321,0.6395406144229603,0.6395406144229603,0.2302346211922657,0.30294029104245485,1.4389663824516605,0.023638051457111467,0.9593109216344403,0.1403869641416254,0.04641827040166647,5.755865529806642,5.755865529806642,0.10278331303226147,0.04660619862191614,0.12378205440444394,0.0029344203567711665,0.20556662606452294,0.0017931045264195148,0.19511408575615735,0.001934419603363012,0.013671889619493212,0.0035951689755194514,1.0465210054193894,0.8222665042580918,0.4604692423845314,1.4389663824516605,0.027873440822308197,1.1511731059613286,0.11397753524369589,0.0018051953990298392,0.17987079780645757,0.014796569485364118,1.1511731059613286,0.004477530556053397,0.007114790518920448,2.877932764903321,0.01541061721501109,3.8372436865377613,0.26163025135484735,0.2502550230350714,0.0365451779670263,0.008234428511883607,0.16929016264137184,0.0697680670279593,0.21720247282289215,0.5755865529806643,3.8372436865377613,0.006522227229242653,0.09136294491756575,0.2807739282832508,0.7674487373075524,2.302346211922657,0.9593109216344403,0.07994257680287004,1.6445330085161836,0.01859730381197623,0.05643005421379061,1.1511731059613286,0.13385733790248006,0.0013846200456595242,2.302346211922657,5.755865529806642,5.755865529806642,0.0015959699236951733,1.6445330085161836,0.20196019402830323,0.010333690358719286,0.013543213011309745,0.0015713528609900744,0.04898608961537568,1.1511731059613286,0.08655436886927281,0.033175017462862486,0.17987079780645757,0.16929016264137184,0.00237600228268592,1.9186218432688806,0.11746664346544167,0.0021790140184768663,0.47965546081722016,0.7674487373075524,0.1576949460220998,0.020892433864996885,0.12790812288459205,0.05534486086352541,0.009949637908049511,3.8372436865377613,11.511731059613284,0.0024265874914867797,0.01887169026166112,2.877932764903321,1.9186218432688806,0.16445330085161836,5.755865529806642,2.877932764903321,0.6395406144229603,1.2790812288459206,0.05873332173272083,0.06395406144229603,11.511731059613284,0.44275888690820325,2.877932764903321,0.8222665042580918,0.1495030007741985,1.6445330085161836,0.06692866895124003,0.30294029104245485,0.47965546081722016,0.0014366318556861706,0.39695624343494085,0.005750115414392251,0.002123543822101694,0.20930420108387787,0.09923906085873521,0.0014182248441066013,0.13231874781164693,11.511731059613284,0.22572021685516244,0.9593109216344403,0.5481776695053945,0.09283654080333294,1.9186218432688806,2.877932764903321,0.08855177738164065,0.025753313332468195,11.511731059613284,0.6058805820849097,0.30294029104245485,0.02218059934414891,1.0465210054193894,0.0010302247234305786,0.1918621843268881,0.016398477292896417,0.006522227229242653,0.003275030173431945,0.7194831912258303,0.0013652432471078372,1.1511731059613286,0.7674487373075524,0.27408883475269724,0.011806903650885419,0.050936863095634,0.16929016264137184,0.018627396536591078,1.4389663824516605,0.002781283174586442,0.005152968245126806,0.0046512044685306205,0.03162563477915738,0.010809137145176792,0.004036371339275345,1.6445330085161836,0.016398477292896417,0.9593109216344403,0.5755865529806643,0.07475150038709925,0.03477864368463228,0.034569762941781636,0.005309839049637124,5.755865529806642,0.002093042010838779,0.002621068091897378,0.021968952403842147,0.016707882524837857,0.0016270997964117717,1.9186218432688806,0.010151438324173973,1.9186218432688806,0.16683668202338095,0.39695624343494085,0.17442016756989825,0.5232605027096947,0.0015634566154574608,0.19511408575615735,0.005673598353678307,0.2807739282832508,2.302346211922657,0.008347883291960323,0.0020418111138015755,0.7194831912258303,0.04796554608172202,5.755865529806642,0.7194831912258303,5.755865529806642,11.511731059613284,0.028707558752152827,0.09136294491756575,0.02586905856092873,0.06189102720222197,0.022977507105016535,3.8372436865377613,1.1511731059613286,0.19847812171747042,5.755865529806642,0.007217386244271652,0.0038565263181284037,0.10098009701415162,1.0465210054193894,0.0325190142926929,0.08281820906196609,0.20196019402830323,0.06615937390582347,0.04737337884614521,0.06893252131504961,0.02646374956232939,3.8372436865377613,0.010417856162545959,2.302346211922657,0.050712471628252355,1.4389663824516605,11.511731059613284,0.011005479024486887,0.4263604096153068,0.003298490274960826,0.07379314781803387,0.1065901024038267,0.09435845130830561,0.0038956788695814837,0.0693477774675499,0.01168703660874445,0.015988515360574006,0.17987079780645757,0.0021939643719484053,0.042794539255067966,0.006283695993238692,0.034569762941781636,0.03270378141935592,0.00644914905300464,0.0018398163751979038,1.9186218432688806,0.3488403351397965,1.1511731059613286,0.00289312165358464,2.877932764903321,0.00424943929849143,0.002829130267784046,0.18871690261661123,0.5755865529806643,0.009763978846152066,0.29517259127213546,0.3289066017032367,2.877932764903321,0.09593109216344405,0.039695624343494086,0.06156005914231702,0.014571811467864917,1.6445330085161836,0.023589612827076403,2.302346211922657,0.6771606505654874,0.4111332521290459,0.31977030721148014,1.1511731059613286,0.0011771889824740039,0.0008832078456048247,0.05162211237494746,0.1621370571776519,0.07332312776823748,0.012391529665891587,0.15147014552122742,0.1576949460220998,0.10561221155608518,0.9593109216344403,0.043605041892474564,0.03762003614252707,0.06256375575876785,0.1265025391166295,0.004352261270175155,0.07062411693014285,0.16929016264137184,0.017903158724126414,0.5481776695053945,0.03902281715123147,1.0465210054193894,0.05588218960977322,0.012028977073786088,0.01918621843268881,3.8372436865377613,2.877932764903321,0.18871690261661123,0.2502550230350714,0.029900600154839703,0.2558162457691841,0.6771606505654874,0.12934529280464363,0.010708587032198404,0.15147014552122742,0.024756410880888785,11.511731059613284,0.9593109216344403,0.0023153119588924546,0.5755865529806643,0.006159299657363982,0.011058339154287498,0.2302346211922657,0.010768691356046103,0.6395406144229603,11.511731059613284,1.2790812288459206,0.15147014552122742,0.011663354670327544,0.02120024136208708,5.755865529806642,2.877932764903321,0.6395406144229603,0.05026956794590954,0.04898608961537568,0.7674487373075524,0.01651611342842652,0.1265025391166295,0.4111332521290459,0.5232605027096947,0.0008565913430771101,0.11176437921954643,0.05933881989491383,0.47965546081722016,0.08341834101169047,0.09136294491756575,0.018214764334831147,0.013737149235815375,0.05049004850707581,0.006222557329520694,2.302346211922657,0.00188253982986317,0.10278331303226147,0.007036510427636482,0.0816434826922928,2.877932764903321,0.06692866895124003,1.6445330085161836,0.002417415174215306,1.2790812288459206,0.4111332521290459,0.023589612827076403,2.877932764903321,0.0028056863416069423,0.01025087360606704,0.002207850222403775,0.07778196661900869,3.8372436865377613,0.23493328693088333,0.9593109216344403,1.0465210054193894,0.5755865529806643,0.5481776695053945,0.3385803252827437,0.0008063695054366268,0.006791581746084533,0.8222665042580918,0.20196019402830323,1.1511731059613286,0.012104869673620698,0.20196019402830323,0.04170917050584524,0.003407854073301742,0.006696760360449845,0.0029502129829864897,0.002620471445393418,0.10278331303226147,0.04232254066034296,0.08787580961536859,0.7194831912258303,0.014777575172802674,0.06431134670175019,0.05304945188761882,0.17987079780645757,0.2131802048076534,0.0078955631410242,1.4389663824516605,5.755865529806642,5.755865529806642,2.877932764903321,0.8855177738164065,0.009657492499675574,1.9186218432688806,0.6395406144229603,0.20196019402830323,1.9186218432688806,0.3488403351397965,0.022440021558700358,0.08281820906196609,1.9186218432688806,0.17987079780645757,0.8855177738164065,0.059034518254427105,0.09359130942775029,0.02218059934414891,0.17442016756989825,3.8372436865377613,0.03799251174789863,0.08721008378494913,0.014796569485364118,1.9186218432688806,0.3289066017032367,0.44275888690820325,0.0031538989204419957,0.12934529280464363,0.4111332521290459,0.5232605027096947,0.0033601083069507544,0.0046662874177597425,0.2302346211922657,0.35974159561291513,0.31112786647603474,0.004974818954024756,3.8372436865377613,3.8372436865377613,0.1495030007741985,0.16445330085161836,5.755865529806642,0.3289066017032367,0.37134616321333175,0.22137944345410163,3.8372436865377613,0.2807739282832508,0.020055280591660774,0.35974159561291513,0.0031704023849113976,0.012054168648809723,0.017765017067304448,0.20556662606452294,0.7674487373075524,0.013339201691324779,0.06732006467610108,1.9186218432688806,0.039695624343494086,0.4263604096153068,0.8222665042580918,0.5232605027096947,0.02120024136208708,0.003660327840894526,0.004972670004152606,3.8372436865377613,0.44275888690820325,0.02074185776506898,0.004257296989501954,2.302346211922657,0.8855177738164065,0.06467264640232182,2.877932764903321,0.008787580961536859,0.08106852858882595,0.008366083618905003,0.07150143515287753,11.511731059613284,0.13081512567742368,0.0816434826922928,0.056988767621847944,0.09136294491756575,0.5005100460701428,2.877932764903321,0.02552490257120462,1.0465210054193894,0.47965546081722016,0.04532177582524915,0.5755865529806643,1.6445330085161836,2.302346211922657,0.9593109216344403,0.3488403351397965,1.2790812288459206,0.30294029104245485,0.0008652834530677454,5.755865529806642,5.755865529806642,0.2807739282832508,0.001131151720508331,0.0012280489715823858,0.0305350956488416,0.12790812288459205,0.002169977579568951,0.47965546081722016,0.03477864368463228,0.10465210054193894,0.02558162457691841,11.511731059613284,0.02403284146057053,1.9186218432688806,0.0014227822345338384,0.12117611641698194,0.005275770421454301,0.0032003700471540963,0.14212013653843558,0.0013549589288622038,0.001417002838455599,0.006665738888021589,0.0013931660486038104,0.0064527640468684325,11.511731059613284,0.11286010842758122,0.3488403351397965,11.511731059613284,0.0951382732199445,0.21720247282289215,0.7194831912258303,0.005432624379241758,0.18871690261661123,0.5005100460701428,0.012862269340350037,0.017181688148676544,0.0016766284677560857,0.0047806192108028585,2.302346211922657,0.22137944345410163,0.5232605027096947,0.05964627492027609,5.755865529806642,0.26163025135484735,0.23493328693088333,5.755865529806642,1.1511731059613286,0.9593109216344403,0.022660887912624574,1.2790812288459206,0.0037867536380306855,0.2131802048076534,0.6058805820849097,2.302346211922657,0.09923906085873521,0.005453212249935236,0.13543213011309746,0.028565089477948596,1.9186218432688806,0.6058805820849097,11.511731059613284,0.16929016264137184,0.4111332521290459,0.005952291137338824,0.08281820906196609,11.511731059613284,0.012776616048405421,2.302346211922657,0.2677146758049601,0.1495030007741985,1.6445330085161836,0.6395406144229603,0.018418769695381258,0.019745679347535648,0.008533529325139573,0.008629483552933496,0.01016039811086786,0.11628011171326551,0.001548316215146373,0.009975503517862463,0.002624653684362354,0.0013786504263009923,0.0015596438232777787,11.511731059613284,1.0465210054193894,11.511731059613284,1.1511731059613286,0.37134616321333175,0.024971217049052676,0.018627396536591078,0.002054565600502103,0.06771606505654873,0.003001755165479344,0.034159439346033486,0.5232605027096947,0.20556662606452294,0.07939124868698817,0.006077999503491702,0.007767699770319355,0.0840272340117758,0.003664989194400918,0.15988515360574007,0.8222665042580918,2.302346211922657,2.302346211922657,0.004105467567622427,0.14212013653843558,0.004612071738627117,1.1511731059613286,0.5481776695053945,0.0015247325906772562,0.0012482900736947825,11.511731059613284,1.6445330085161836,0.037867536380306856,0.006398961122631063,0.020556662606452294,0.3289066017032367,0.39695624343494085,0.008754168106169798,0.16929016264137184,0.04170917050584524,0.27408883475269724,0.07573507276061371,0.28779327649033215,0.05508005291680997,0.002356064482114876,0.012181725989008768,0.18567308160666587,0.0030903975998961834,11.511731059613284,0.09839086375737852,0.005220739709575186,0.00406057532966959,0.00379299211189894,5.755865529806642,0.3488403351397965,0.23493328693088333,0.07524007228505414,1.9186218432688806,0.03597415956129152,0.051391656516130736,0.37134616321333175,0.17181688148676544,0.2558162457691841,0.18567308160666587,0.027343779238986423,0.16445330085161836,0.0196111261662918,0.09209384847690628,0.04796554608172202,0.10098009701415162,0.00501600481900361,0.006840006571368559,0.000933030560837517,0.039155547821813894,0.29517259127213546,0.006840006571368559,0.035312058465071426,0.027214494230764264,0.03762003614252707,0.08527208192306138,0.2558162457691841,0.0052042183813803275,0.011663354670327544,0.001703927036650871,0.14389663824516608,0.001577381619568825,0.2449304480768784,0.03876003723775516,0.005251702125735987,1.6445330085161836,0.004802557805428988,0.7194831912258303,11.511731059613284,0.7674487373075524,0.08721008378494913,0.0014747285497839207,0.006406082949144844,2.877932764903321,0.034466260657524804,0.7674487373075524,0.09283654080333294,0.09593109216344405,0.10561221155608518,0.37134616321333175,0.8855177738164065,0.8222665042580918,0.0012566020150216444,0.0701934820708127,5.755865529806642,0.030214517216832767,0.14212013653843558,0.30294029104245485,0.0023157777227144002,0.1771035547632813,0.003415943934603348,0.00876750271105353,0.05049004850707581,11.511731059613284,1.1511731059613286,3.8372436865377613,0.3488403351397965,0.7194831912258303,0.18871690261661123,2.877932764903321,0.0951382732199445,0.05508005291680997,0.5481776695053945,0.11511731059613285,0.0037509713455892097,0.09359130942775029,11.511731059613284,11.511731059613284,0.7674487373075524,0.16929016264137184,0.0042588720161351405,0.007944603905875283,0.29517259127213546,0.10561221155608518,1.6445330085161836,0.5005100460701428,11.511731059613284,0.2131802048076534,0.11746664346544167,0.1918621843268881,0.26163025135484735,0.014142175748910668,0.048572704892883053,0.4263604096153068,0.08222665042580918,0.23493328693088333,0.003960003804476534,0.0010212678370842161,0.10758627158517087,0.057272293828921815,0.8855177738164065,0.16683668202338095,0.4111332521290459,0.056988767621847944,0.04550091327910389,0.0024017798997732704,0.44275888690820325,0.0025874873139162245,0.5481776695053945,0.0027029187742693785,0.04247871239709699,0.1918621843268881,0.7194831912258303,0.09359130942775029,0.09673723579506961,0.14389663824516608,0.04295422037169136,0.008655436886927282,0.2302346211922657,0.09923906085873521,0.5755865529806643,0.0021149606943989133,0.0144257281448788]
# bili = [0.10323814442648493,1.0238571938076166,3.5233568556561834,0.14964795247141854,0.19605776051635213,0.03693841864800837,1.610136197477288,0.023678473492313057,0.015154223035080357,0.03693841864800837,0.9641874406069878,16.528521636574208,0.0066299725778476565,0.05872261426093638,0.8344294058691121,0.03409700182893081,0.007577111517540178,0.0805068098738644,1.0532185009380848,0.010418528336617746,0.021784195612928013,0.27751170932990904,2.5781121938430456,0.12881089579818303,0.9177776325620541,0.063458308959399,0.9926016087977634,0.15438364716988115,4.04428327248707,0.007577111517540178,0.002841416819077567,0.42337110604255745,0.03977983546708594,3.700471837378685,3.7383573949663855,8.085725128155064,0.3523356855656183,0.005682833638155134,0.008524250457232702,0.0009471389396925223,0.7150898994678544,0.011365667276310268,1.4737481901615648,0.23015476234528295,47.87976767933639,0.017995639854157922,0.08713678245171205,0.2074234277926624,0.002841416819077567,5.594749716763729,0.003788555758770089,0.002841416819077567,0.6696272303626133,0.11270953382341016,0.02841416819077567,0.38264413163577904,0.9594517459085251,2.5553808592904255,8.550770347544091,2.4019443510602367,3.773401535735009,0.05303978062278125,0.005682833638155134,0.04451553016554855,0.3182386837366875,1.146038117027952,0.05019836380370368,0.8221165996531093,0.024625612432005582,0.14680653565234097,0.002841416819077567,1.2985274863184482,0.21878909506897265,0.018942778793850448,1.8061939579936401,1.0124915265313064,2.02403591412292,0.0018942778793850446,0.1780621206621942,7.657618327414043,1.1763465630981127,0.003788555758770089,1.1621394790027249,0.19226920475758202,0.008524250457232702,0.5588119744185882,4.13805002751663,3.48831271488756,0.5578648354788956,4.142785722215092,0.05398691956247377,0.09092533821048214,0.0018942778793850446,4.324636398636057,0.7359269561410898,0.9708174131848354,0.29456021024437445,0.02083705667323549,10.94608472602648,0.015154223035080357,0.011365667276310268,0.17048500914465403,0.05682833638155134,0.29456021024437445,0.021784195612928013,0.0009471389396925223,0.20268773309419977,0.38453840951516405,0.14585939671264844,2.912452239554506,0.11744522852187277,0.2992959049428371,0.002841416819077567,1.2019193144698108,0.5900675594284414,2.002251718509992,0.01610136197477288,9.453393757071066,0.0018942778793850446,0.17995639854157922,0.04072697440677846,0.11839236746156528,0.0009471389396925223,0.043568391225856026,10.665731599877494,0.009471389396925224,31.589925055564695,0.10702670018525502,0.4157939945250173,0.014207084095387835,0.009471389396925224,3.9723007130704384,7.547750210409711,0.014207084095387835,0.05019836380370368,0.005682833638155134,1.0835269470082456,0.34002287934961556,5.027413491887909,0.0009471389396925223,0.08429536563263448,0.035991279708315844,7.439776371284762,0.02083705667323549,0.08334822669294197,3.048840246870229,0.003788555758770089,0.11176239488371763,0.01610136197477288,6.203760054986022,0.002841416819077567,0.11176239488371763,0.07955967093417188,11.522892340299226,0.008524250457232702,0.13638800731572323,0.20552914991327734,0.5588119744185882,0.003788555758770089,1.2748490128261352,0.017995639854157922,0.21784195612928015,0.01988991773354297,0.003788555758770089,0.07577111517540179,0.07198255941663169,0.025572751371698104,0.014207084095387835,1.6859073126526898,0.04167411334647098,1.3297830713283012,0.013259945155695313,3.1075628611311656,0.07955967093417188,0.2917187934252969,0.2803531261489866,7.467243400535846,0.39211552103270425,0.018942778793850448,0.013259945155695313,6.981361124473582,0.08997819927078961,2.175578144473724,0.05682833638155134,0.2377318738628231,0.2850888208474492,0.04262125228616351,0.03220272394954576,2.3403803199802224,0.15817220292865122,0.09660817184863726,1.3487258501221517,0.02083705667323549,4.061331773401536,0.5019836380370368,0.027467029251083148,0.10134386654709988,0.10039672760740737,0.20647628885296987,0.09092533821048214,0.1827978153606568,0.0018942778793850446,0.6023803656444442,5.013206407792521,0.025572751371698104,0.08240108775324945,9.971478757082874,0.8789449360346607,0.009471389396925224,0.0009471389396925223,0.015154223035080357,0.11555095064248773,0.02083705667323549,0.014207084095387835,0.02083705667323549,0.046409808044933595,17.094910722510335,0.21878909506897265,0.04830408592431863,0.1951106215766596,0.03125558500985324,0.011365667276310268,0.07008828153724665,0.014207084095387835,2.2608206490460505,0.9802888025817605,0.046409808044933595,0.035044140768623326,0.8628435740598879,2.7485972029876997,0.012312806216002791,10.93850761450894,0.014207084095387835,0.0009471389396925223,0.37127846435946876,0.017995639854157922,0.0018942778793850446,0.002841416819077567,0.8552664625423476,0.012312806216002791,0.3949569378517818,0.2509918190185184,0.3352871846511529,0.0018942778793850446,0.038832696527393414,0.5124021663736545,0.01988991773354297,0.16953787020496147,0.07577111517540179,0.0066299725778476565,0.0009471389396925223,1.3070517367756809,0.7955967093417188,0.527556389408735,0.28698309872683425,0.10039672760740737,0.035991279708315844,0.002841416819077567,0.2547803747772885,0.03314986288923828,0.8533721846629626,0.0009471389396925223,0.1865863711194269,0.05966975320062891,0.007577111517540178,0.10229100548679242,0.2850888208474492,0.03409700182893081,0.0009471389396925223,0.0009471389396925223,2.535490941556882,0.8827334917934309,0.04451553016554855,0.10513242230586999,0.0009471389396925223,0.3693841864800837,3.925890905025505,0.2670931809932913,0.015154223035080357,0.12502234003941295,0.0009471389396925223,0.003788555758770089,0.25856893053605856,0.25667465265667355,0.6715215082419983,0.030308446070160713,0.0066299725778476565,0.2888773766062193,0.015154223035080357,0.06819400365786162,0.0009471389396925223,0.012312806216002791,0.037885557587700895,0.09187247715017467,0.0009471389396925223,2.599896389455974,2.827209734982179,3.865274012885184,1.681171617954227,0.003788555758770089,0.004735694698462612,0.0009471389396925223,1.8185067642096429,0.017048500914465404,0.47262233090656863,0.3087672943397623,0.0066299725778476565,0.014207084095387835,1.7834626234410196,0.009471389396925224,0.06156403108001395,0.1411237020141858,0.0009471389396925223,0.011365667276310268,0.11744522852187277,0.005682833638155134,0.011365667276310268,0.027467029251083148,0.5067193327354994,0.047356946984626114,0.004735694698462612,0.4830408592431864,0.011365667276310268,1.7351585375167007,0.055881197441858814,0.009471389396925224,0.14396511883326338,0.037885557587700895,0.12123378428064285,6.621448327390424,0.13259945155695313,0.022731334552620535,0.0009471389396925223,0.11933950640125782,0.09376675502955971,0.03314986288923828,0.08145394881355691,2.86130673681111,0.018942778793850448,0.052092641683088727,0.1790092596018867,1.4519639945486367,0.01610136197477288,4.3918832633542255,0.07577111517540179,1.5372064991209637,1.5419421938194262,0.018942778793850448,0.0018942778793850446,4.267808062254505,6.794774753354155,0.002841416819077567,0.022731334552620535,0.0009471389396925223,0.002841416819077567,0.010418528336617746,0.0975553107883298,1.6925372852305374,0.1231280621600279,0.018942778793850448,1.5741449177689721,0.010418528336617746,0.08429536563263448,0.0018942778793850446,0.023678473492313057,0.014207084095387835,0.29550734918406696,0.009471389396925224,0.5038779159164218,0.1449122577729559,0.030308446070160713,0.21121198355143248,0.3002430438825296,0.008524250457232702,0.5777547532124386,0.0018942778793850446,0.33339290677176786,2.54212091413473,0.6942528427946189,0.3769612979976239,0.0018942778793850446,0.0018942778793850446,0.035991279708315844,0.046409808044933595,3.856749762427951,0.07387683729601674,11.281371910677635,0.0018942778793850446,0.007577111517540178,7.507970374942624,0.021784195612928013,2.6917688666061483,0.07198255941663169,0.2898245155459118,0.14396511883326338,0.022731334552620535,0.0018942778793850446,0.0009471389396925223,0.055881197441858814,0.023678473492313057,1.0323814442648493,0.03409700182893081,0.07292969835632422,0.6307945338352199,0.012312806216002791,0.08997819927078961,0.0066299725778476565,0.04546266910524107,0.7264555667441647,0.03693841864800837,2.9077165448560436,0.04072697440677846,0.03693841864800837,0.0009471389396925223,0.7700239579700207,0.014207084095387835,0.08524250457232702,0.049251224864011164,0.31918582267638007,0.0009471389396925223,1.612030475356673,5.043514853862681,0.027467029251083148,0.1988991773354297,0.038832696527393414,0.004735694698462612,0.008524250457232702,0.002841416819077567,0.6980413985533889,3.016637522920684,0.013259945155695313,0.004735694698462612,0.030308446070160713,0.01610136197477288,0.13922942413480077,0.10892097806464007,1.0001787203153036,0.05019836380370368,0.002841416819077567,0.14301797989357087,0.16953787020496147,0.15627792504926616,0.063458308959399,0.5019836380370368,1.3809285740716977,0.0018942778793850446,0.49724794333857425,0.09092533821048214,0.03125558500985324,0.07955967093417188,6.636602550425504,1.024804332747309,0.2926659323649894,0.017048500914465404,0.20647628885296987,0.009471389396925224,0.04546266910524107,0.0018942778793850446,1.044694250480852,0.046409808044933595,3.7506702011823885,0.08145394881355691,0.02841416819077567,0.28698309872683425,0.02083705667323549,0.03314986288923828,0.0066299725778476565,0.038832696527393414,2.9711748538154428,0.013259945155695313,0.1146038117027952,0.038832696527393414,0.03693841864800837,2.208728007362962,0.07955967093417188,0.035044140768623326,0.29361307130468195,0.003788555758770089,0.008524250457232702,0.010418528336617746,0.003788555758770089,0.017048500914465404,0.017048500914465404,0.047356946984626114,0.035991279708315844,0.007577111517540178,0.4612566636302584,0.011365667276310268,0.07766539305478683,0.23489045704374553,0.0018942778793850446,0.0018942778793850446,0.1060795612455625,0.23394331810405303,0.08808392139140457,3.715626060413765,0.05303978062278125,6.080631992825993,0.055881197441858814,5.636423830110201,0.7974909872211038,3.0327388848954566,0.010418528336617746,0.013259945155695313,0.023678473492313057,0.007577111517540178,0.3911683820930117,0.009471389396925224,0.09566103290894476,6.039905018419215,0.06061689214032143,0.7368740950807824,0.009471389396925224,2.435094213949475,1.5324708044225013,0.003788555758770089,0.7075127879503141,0.002841416819077567,0.04167411334647098,0.043568391225856026,0.2983487660031445,1.3241002376901463,0.06440544789909151,0.15627792504926616,0.05019836380370368,0.018942778793850448,0.002841416819077567,1.6717002285573017,0.11933950640125782,0.038832696527393414,0.014207084095387835,0.004735694698462612,0.011365667276310268,0.13638800731572323,0.0066299725778476565,0.5862790036696713,0.19321634369727453,0.009471389396925224,0.08145394881355691,7.874513144603631,0.004735694698462612,0.0018942778793850446,0.0018942778793850446,6.831713172002163,0.0066299725778476565,0.05398691956247377,1.05511277881747,0.805068098738644,6.938739872187418,0.22257765082774275,0.009471389396925224,0.12596947897910546,0.3286572120733052,0.06061689214032143,0.06440544789909151,4.588888162810271,0.005682833638155134,0.09281961608986719,5.003735018395595,0.022731334552620535,0.014207084095387835,0.06914114259755413,0.5218735557705798,0.08524250457232702,0.19700489945604466,1.0958397532242483,0.002841416819077567,0.0009471389396925223,4.493227129901326,0.5777547532124386,0.003788555758770089,0.005682833638155134,0.06629972577847656,0.0018942778793850446,0.003788555758770089,0.017048500914465404,0.008524250457232702,0.18563923217973438,0.17048500914465403,0.0009471389396925223,0.024625612432005582,0.003788555758770089,0.013259945155695313,0.07292969835632422,0.0066299725778476565,0.16290789762711383,0.035991279708315844,0.022731334552620535,7.589424323756181,0.027467029251083148,1.8961721572644297,5.134440192073163,0.052092641683088727,0.10986811700433259,7.687926773484203,0.08240108775324945,0.0009471389396925223,0.04830408592431863,0.011365667276310268,0.01988991773354297,0.11744522852187277,0.005682833638155134,0.003788555758770089,0.1231280621600279,0.42337110604255745,0.0009471389396925223,0.017995639854157922,0.035991279708315844,0.49156510970041906,0.010418528336617746,10.583330512124245,0.05682833638155134,0.6648915356641506,1.6717002285573017,3.329193373019216,0.015154223035080357,7.986275539487348,0.009471389396925224,0.014207084095387835,0.03977983546708594,0.9234604662002093,0.21405340037051004,0.06440544789909151,0.5853318647299788,0.007577111517540178,3.92020807138735,2.115908391273095,2.3441688757389927,0.34475857404807814,1.0087029707725363,2.7012402560030737,0.0066299725778476565,0.6648915356641506,0.011365667276310268,0.018942778793850448,0.14585939671264844,0.31350298903822493,0.31539726691760994,2.0533972212533884,0.0018942778793850446,5.209264168308873,4.159834223129558,0.4963008043988817,0.6525787294481479,6.701007998324596,0.005682833638155134,1.0740555576113202,0.005682833638155134,0.06535258683878403,0.027467029251083148,0.06251117001970648,0.02083705667323549,6.973784012956042,0.055881197441858814,1.9217449086361278,0.038832696527393414,0.004735694698462612,1.3061045978359882,5.33996934198644,0.015154223035080357,0.22731334552620536,0.0018942778793850446,0.015154223035080357,0.0018942778793850446,0.0009471389396925223,0.3798027148167014,0.11933950640125782,0.42147682816317245,0.17616784278280914,0.4745166087859537,0.002841416819077567,0.009471389396925224,0.054934058502166296,0.0018942778793850446,1.5106866088095732,2.827209734982179,0.10797383912494754,0.010418528336617746,0.3352871846511529,0.1316523126172606,0.05398691956247377,0.1648021755064989,0.23015476234528295,0.15817220292865122,0.4120054387662472,0.002841416819077567,1.0465885283602372,0.004735694698462612,0.21500053931020258,0.007577111517540178,0.0009471389396925223,0.9907073309183784,0.025572751371698104,3.3055148995269032,0.14775367459203348,0.10229100548679242,0.11555095064248773,2.7987955667914037,0.15722506398895872,0.9329318555971345,0.6819400365786161,0.06061689214032143,4.969638016566664,0.2547803747772885,1.7351585375167007,0.31539726691760994,0.33339290677176786,1.6906430073511522,5.926248345656112,0.005682833638155134,0.03125558500985324,0.009471389396925224,3.7686658410365466,0.003788555758770089,2.565799387627043,3.8539083456088736,0.057775475321243865,0.018942778793850448,1.1166768098974837,0.03693841864800837,0.03314986288923828,0.003788555758770089,0.11365667276310268,0.27467029251083147,0.17711498172250167,0.7482397623570927,0.0066299725778476565,0.4622038025699509,0.004735694698462612,0.01610136197477288,0.026519890311390626,0.03409700182893081,0.009471389396925224,9.262071691253176,12.345008939952335,0.21121198355143248,0.06724686471816908,0.148700813531726,0.8798920749743533,0.07198255941663169,0.06914114259755413,0.10323814442648493,0.011365667276310268,0.2500446800788259,0.2898245155459118,0.1742735649034241,0.08618964351201953,2.505182495486722,0.15438364716988115,0.06440544789909151,0.6090103382222919,0.01988991773354297,0.2794059872092941,0.010418528336617746,0.1951106215766596,0.9064119652857439,0.5682833638155134,0.002841416819077567,0.003788555758770089,0.057775475321243865,0.043568391225856026,0.36464849178162106,0.04262125228616351,0.01610136197477288,0.08429536563263448,1.0181743601694615,0.07198255941663169,0.4404196069570229,0.0009471389396925223,0.011365667276310268,4.7091748081512215,0.018942778793850448,1.7702026782853242,0.9859716362199158,0.047356946984626114,1.0124915265313064,0.017048500914465404,0.0009471389396925223,0.008524250457232702,0.07198255941663169,0.9348261334765195,0.5142964442530397,0.0018942778793850446,0.003788555758770089,0.017048500914465404,0.21689481718958759,0.22257765082774275,0.014207084095387835,0.6601558409656881,0.08618964351201953,0.026519890311390626,0.02083705667323549,12.728600210527807,0.0975553107883298,0.18374495430034934,0.022731334552620535,0.13070517367756807,0.11933950640125782,0.5985918098856742,0.7937024314623337,0.21594767824989508,1.7522070384311663,0.004735694698462612,5.791754616219774,0.1060795612455625,1.5495193053369667,0.13354659049664566,0.003788555758770089,0.16290789762711383,0.0066299725778476565,4.510275630815792,0.008524250457232702,0.026519890311390626,0.4622038025699509,0.003788555758770089,3.886111069558419,1.0636370292747026,4.9383824315568114,0.1401765630744933,0.002841416819077567,0.046409808044933595,0.011365667276310268,0.010418528336617746,0.018942778793850448,0.01988991773354297,0.03220272394954576,13.521355503050447,1.6054005027788252,0.013259945155695313,0.05398691956247377,0.009471389396925224,0.9007291316475888,0.05398691956247377,0.26141034735513613,3.1994353382813405,1.6281318373314457,3.695736142680222,4.16078136206925,0.1060795612455625,0.25762179159636606,0.12407520109972042,0.015154223035080357,0.7378212340204748,0.16953787020496147,0.20552914991327734,0.06061689214032143,0.05114550274339621,1.3809285740716977,0.007577111517540178,0.0018942778793850446,0.0018942778793850446,0.003788555758770089,0.012312806216002791,1.1289896161134865,0.005682833638155134,0.017048500914465404,0.05398691956247377,0.005682833638155134,0.03125558500985324,0.4858822760622639,0.1316523126172606,0.005682833638155134,0.06061689214032143,0.012312806216002791,0.18469209324004185,0.11649808958218025,0.49156510970041906,0.06251117001970648,0.002841416819077567,0.28698309872683425,0.12502234003941295,0.7368740950807824,0.005682833638155134,0.03314986288923828,0.024625612432005582,3.457057129877706,0.08429536563263448,0.026519890311390626,0.02083705667323549,3.2448980073865816,2.3365917642214526,0.047356946984626114,0.030308446070160713,0.035044140768623326,2.1916795064484966,0.002841416819077567,0.002841416819077567,0.07292969835632422,0.06629972577847656,0.0018942778793850446,0.03314986288923828,0.02936130713046819,0.049251224864011164,0.002841416819077567,0.038832696527393414,0.5436577513835078,0.030308446070160713,3.4390614900235486,0.9045176874063589,0.6137460329207545,0.05303978062278125,0.014207084095387835,0.8173809049546468,0.16196075868742132,0.005682833638155134,0.27467029251083147,0.025572751371698104,0.013259945155695313,0.02083705667323549,0.5142964442530397,2.978751965332983,2.1926266453881893,0.002841416819077567,0.024625612432005582,0.5256621115293499,2.5610636929285806,0.004735694698462612,0.012312806216002791,0.16859073126526897,0.003788555758770089,1.2407520109972043,0.13449372943633817,1.3032631810169106,0.15248936929049609,0.0009471389396925223,0.08334822669294197,0.13354659049664566,0.19132206581788952,0.11933950640125782,0.021784195612928013,0.003788555758770089,0.42715966180132753,0.010418528336617746,0.022731334552620535,0.24057329068190064,0.018942778793850448,0.0066299725778476565,0.004735694698462612,0.011365667276310268,0.03125558500985324,0.008524250457232702,0.035991279708315844,12.600736453669317,0.0018942778793850446,0.0018942778793850446,0.038832696527393414,9.6390329892508,8.878480420677704,0.3570713802640809,0.08524250457232702,5.024572075068831,0.022731334552620535,0.31350298903822493,0.10418528336617745,0.426212522861635,0.0009471389396925223,0.45367955211271815,0.005682833638155134,7.663301161052198,0.08997819927078961,2.0666571664090836,3.4068587660740026,0.07671825411509431,8.04689243162767,7.694556746062051,1.6357089488489862,7.826209058679312,1.6896958684114598,0.0009471389396925223,0.09660817184863726,0.03125558500985324,0.0009471389396925223,0.1146038117027952,0.05019836380370368,0.015154223035080357,2.0069874132084546,0.057775475321243865,0.021784195612928013,0.8476893510248076,0.6345830895939899,6.503055959928858,2.2807105667795935,0.004735694698462612,0.049251224864011164,0.02083705667323549,0.1827978153606568,0.0018942778793850446,0.04167411334647098,0.046409808044933595,0.0018942778793850446,0.009471389396925224,0.011365667276310268,0.4811465813638013,0.008524250457232702,2.8793023766652674,0.05114550274339621,0.017995639854157922,0.004735694698462612,0.10986811700433259,1.9994103016909146,0.0805068098738644,0.38169699269608653,0.005682833638155134,0.017995639854157922,0.0009471389396925223,0.06440544789909151,0.026519890311390626,1.8317667093653383,0.1316523126172606,0.0009471389396925223,0.8533721846629626,0.004735694698462612,0.04072697440677846,0.07292969835632422,0.0066299725778476565,0.017048500914465404,0.5919618373078264,0.5521820018407405,1.2776904296452127,1.2634833455498247,1.0731084186716278,0.09376675502955971,7.041978016613903,1.0929983364051707,4.154151389491403,7.9086101464325615,6.990832513870507,0.0009471389396925223,0.010418528336617746,0.0009471389396925223,0.009471389396925224,0.02936130713046819,0.4366310511982528,0.5853318647299788,5.306819479097203,0.1610136197477288,3.632277833720823,0.31918582267638007,0.02083705667323549,0.05303978062278125,0.13733514625541574,1.7938811517776372,1.4036599086243182,0.12975803473787556,2.9749634095742126,0.06819400365786162,0.013259945155695313,0.004735694698462612,0.004735694698462612,2.6557775868978326,0.07671825411509431,2.3640587934725357,0.009471389396925224,0.01988991773354297,7.150898994678544,8.734515301844441,0.0009471389396925223,0.0066299725778476565,0.28793023766652676,1.7039029525068476,0.5303978062278125,0.03314986288923828,0.027467029251083148,1.2454877056956668,0.06440544789909151,0.26141034735513613,0.03977983546708594,0.14396511883326338,0.037885557587700895,0.19795203839573716,4.627720859337664,0.8950462980094336,0.05872261426093638,3.528092550354646,0.0009471389396925223,0.11081525594402511,2.0884413620220115,2.685138894028301,2.874566681966805,0.0018942778793850446,0.03125558500985324,0.046409808044933595,0.1449122577729559,0.005682833638155134,0.30308446070160716,0.212159122491125,0.02936130713046819,0.063458308959399,0.04262125228616351,0.05872261426093638,0.3987454936105519,0.06629972577847656,0.5559705575995106,0.11839236746156528,0.22731334552620536,0.10797383912494754,2.1736838665943385,1.5940348355025151,11.68580023792634,0.27845884826960154,0.03693841864800837,1.5940348355025151,0.3087672943397623,0.40063977148993696,0.2898245155459118,0.12786375685849052,0.04262125228616351,2.0950713345998593,0.9348261334765195,6.398870676562681,0.07577111517540179,6.912219981876028,0.04451553016554855,0.2813002650886791,2.076128555806009,0.0066299725778476565,2.270292038442976,0.015154223035080357,0.0009471389396925223,0.014207084095387835,0.12502234003941295,7.393366563239829,1.7020086746274627,0.003788555758770089,0.31634440585730245,0.014207084095387835,0.11744522852187277,0.11365667276310268,0.10323814442648493,0.02936130713046819,0.012312806216002791,0.013259945155695313,8.676739826523196,0.15533078610957365,0.0018942778793850446,0.36085993602285105,0.07671825411509431,0.035991279708315844,4.708227669211529,0.06156403108001395,3.1918582267638005,1.2435934278162817,0.21594767824989508,0.0009471389396925223,0.009471389396925224,0.002841416819077567,0.03125558500985324,0.015154223035080357,0.057775475321243865,0.003788555758770089,0.1146038117027952,0.19795203839573716,0.01988991773354297,0.09471389396925223,2.906769405916351,0.11649808958218025,0.0009471389396925223,0.0009471389396925223,0.014207084095387835,0.06440544789909151,2.560116553988888,1.3724043236144647,0.03693841864800837,0.10323814442648493,0.0066299725778476565,0.021784195612928013,0.0009471389396925223,0.05114550274339621,0.09281961608986719,0.05682833638155134,0.04167411334647098,0.7709710969097131,0.2244719287071278,0.025572751371698104,0.13259945155695313,0.046409808044933595,2.753332897686162,10.676150128214111,0.10134386654709988,0.190374926878197,0.012312806216002791,0.06535258683878403,0.026519890311390626,0.19132206581788952,0.23962615174220814,4.53963693794626,0.024625612432005582,4.213821142692032,0.01988991773354297,4.033864744150453,0.25667465265667355,0.05682833638155134,0.015154223035080357,0.11649808958218025,0.11270953382341016,0.07577111517540179,0.253833235837596,1.2596947897910546,0.047356946984626114,0.10986811700433259,0.018942778793850448,5.1552772487463985,0.7558168738746328]

class HookBase:
    """
    Base class for hooks that can be registered with :class:`TrainerBase`.

    Each hook can implement 4 methods. The way they are called is demonstrated
    in the following snippet:

    .. code-block:: python

        hook.before_train()
        for iter in range(start_iter, max_iter):
            hook.before_step()
            trainer.run_step()
            hook.after_step()
        hook.after_train()

    Notes:
        1. In the hook method, users can access `self.trainer` to access more
           properties about the context (e.g., current iteration).

        2. A hook that does something in :meth:`before_step` can often be
           implemented equivalently in :meth:`after_step`.
           If the hook takes non-trivial time, it is strongly recommended to
           implement the hook in :meth:`after_step` instead of :meth:`before_step`.
           The convention is that :meth:`before_step` should only take negligible time.

           Following this convention will allow hooks that do care about the difference
           between :meth:`before_step` and :meth:`after_step` (e.g., timer) to
           function properly.

    Attributes:
        trainer: A weak reference to the trainer object. Set by the trainer when the hook is
            registered.
    """

    def before_train(self):
        """
        Called before the first iteration.
        """
        pass

    def after_train(self):
        """
        Called after the last iteration.
        """
        pass

    def before_step(self):
        """
        Called before each iteration.
        """
        pass

    def after_step(self):
        """
        Called after each iteration.
        """
        pass


class TrainerBase:
    """
    Base class for iterative trainer with hooks.

    The only assumption we made here is: the training runs in a loop.
    A subclass can implement what the loop is.
    We made no assumptions about the existence of dataloader, optimizer, model, etc.

    Attributes:
        iter(int): the current iteration.

        start_iter(int): The iteration to start with.
            By convention the minimum possible value is 0.

        max_iter(int): The iteration to end training.

        storage(EventStorage): An EventStorage that's opened during the course of training.
    """

    def __init__(self):
        self._hooks = []

    def register_hooks(self, hooks):
        """
        Register hooks to the trainer. The hooks are executed in the order
        they are registered.

        Args:
            hooks (list[Optional[HookBase]]): list of hooks
        """
        hooks = [h for h in hooks if h is not None]
        for h in hooks:
            assert isinstance(h, HookBase)
            # To avoid circular reference, hooks and trainer cannot own each other.
            # This normally does not matter, but will cause memory leak if the
            # involved objects contain __del__:
            # See http://engineering.hearsaysocial.com/2013/06/16/circular-references-in-python/
            h.trainer = weakref.proxy(self)
        self._hooks.extend(hooks)

    def train(self, start_iter: int, max_iter: int):
        """
        Args:
            start_iter, max_iter (int): See docs above
        """
        logger = logging.getLogger(__name__)
        logger.info("Starting training from iteration {}".format(start_iter))

        self.iter = self.start_iter = start_iter
        self.max_iter = max_iter
        ratio = bili
        Total_acc = []
        class_acc = list(np.zeros(1203))
        class_num = list(np.zeros(1203))
        with EventStorage(start_iter) as self.storage:
            try:
                self.before_train()
                for self.iter in range(start_iter, max_iter):
                    # print('*********************************iter***************************', self.iter)
                    self.before_step()
                    pred_class_logits, gt_classes = self.run_step(ratio=ratio, iter=self.iter)
                    acc_class, num_class = accuracy(pred_class_logits, gt_classes)
                    for i, (acc, num) in enumerate(zip(acc_class, num_class)):
                        class_acc[i] += acc
                        class_num[i] += num
                    # for i in range(len(num_class)):
                    #     self.storage.put_scalar("mask_rcnn/class{} accuracy".format(i),
                    #                        [i / (j + np.finfo(np.float32).eps) for i, j in zip(class_acc, class_num)][i])
                    if (self.iter+1) % 6211 == 0:
                        Acc = [i / (j + np.finfo(np.float32).eps) for i, j in zip(class_acc, class_num)]
                        Total_acc.append(Acc)
                        print('Get ACC:', Acc)
                        if (self.iter+1) / 6211 == 1:
                            ratio = Acc
                            class_acc = list(np.zeros(1203))
                            class_num = list(np.zeros(1203))
                        else:
                            ratio = [0.8 * i + 0.2 * j for i, j in zip(Acc, ratio)]
                            class_acc = list(np.zeros(1203))
                            class_num = list(np.zeros(1203))
                    self.after_step()
                f = open('Acc.txt', 'w')
                k = ','.join(str(j) for j in Total_acc)
                k = '[' + k + ']'
                f.write(k)
                f.close()
            except Exception:
                logger.exception("Exception during training:")
                raise
            finally:
                self.after_train()

    def before_train(self):
        for h in self._hooks:
            h.before_train()

    def after_train(self):
        for h in self._hooks:
            h.after_train()

    def before_step(self):
        for h in self._hooks:
            h.before_step()

    def after_step(self):
        for h in self._hooks:
            h.after_step()
        # this guarantees, that in each hook's after_step, storage.iter == trainer.iter
        self.storage.step()

    def run_step(self):
        raise NotImplementedError


class SimpleTrainer(TrainerBase):
    """
    A simple trainer for the most common type of task:
    single-cost single-optimizer single-data-source iterative optimization.
    It assumes that every step, you:

    1. Compute the loss with a data from the data_loader.
    2. Compute the gradients with the above loss.
    3. Update the model with the optimizer.

    If you want to do anything fancier than this,
    either subclass TrainerBase and implement your own `run_step`,
    or write your own training loop.
    """

    def __init__(self, model, data_loader, optimizer):
        """
        Args:
            model: a torch Module. Takes a data from data_loader and returns a
                dict of losses.
            data_loader: an iterable. Contains data to be used to call model.
            optimizer: a torch optimizer.
        """
        super().__init__()

        """
        We set the model to training mode in the trainer.
        However it's valid to train a model that's in eval mode.
        If you want your model (or a submodule of it) to behave
        like evaluation during training, you can overwrite its train() method.
        """
        model.train()

        self.model = model
        self.data_loader = data_loader
        self._data_loader_iter = iter(data_loader)
        self.optimizer = optimizer

    def run_step(self):
        """
        Implement the standard training logic described above.
        """
        assert self.model.training, "[SimpleTrainer] model was changed to eval mode!"
        start = time.perf_counter()
        """
        If you want to do something with the data, you can wrap the dataloader.
        """
        data = next(self._data_loader_iter)
        data_time = time.perf_counter() - start

        """
        If you want to do something with the losses, you can wrap the model.
        """
        loss_dict = self.model(data)
        losses = sum(loss_dict.values())
        self._detect_anomaly(losses, loss_dict)

        metrics_dict = loss_dict
        metrics_dict["data_time"] = data_time
        self._write_metrics(metrics_dict)

        """
        If you need to accumulate gradients or something similar, you can
        wrap the optimizer with your custom `zero_grad()` method.
        """
        self.optimizer.zero_grad()
        losses.backward()

        """
        If you need gradient clipping/scaling or other processing, you can
        wrap the optimizer with your custom `step()` method.
        """
        self.optimizer.step()

    def _detect_anomaly(self, losses, loss_dict):
        if not torch.isfinite(losses).all():
            raise FloatingPointError(
                "Loss became infinite or NaN at iteration={}!\nloss_dict = {}".format(
                    self.iter, loss_dict
                )
            )

    def _write_metrics(self, metrics_dict: dict):
        """
        Args:
            metrics_dict (dict): dict of scalar metrics
        """
        metrics_dict = {
            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)
            for k, v in metrics_dict.items()
        }
        # gather metrics among all workers for logging
        # This assumes we do DDP-style training, which is currently the only
        # supported method in detectron2.
        all_metrics_dict = comm.gather(metrics_dict)

        if comm.is_main_process():
            if "data_time" in all_metrics_dict[0]:
                # data_time among workers can have high variance. The actual latency
                # caused by data_time is the maximum among workers.
                data_time = np.max([x.pop("data_time") for x in all_metrics_dict])
                self.storage.put_scalar("data_time", data_time)

            # average the rest metrics
            metrics_dict = {
                k: np.mean([x[k] for x in all_metrics_dict]) for k in all_metrics_dict[0].keys()
            }
            total_losses_reduced = sum(loss for loss in metrics_dict.values())

            self.storage.put_scalar("total_loss", total_losses_reduced)
            if len(metrics_dict) > 1:
                self.storage.put_scalars(**metrics_dict)


# Copyright (c) OpenMMLab. All rights reserved.

import torch.nn as nn
import numpy as np

def accuracy(pred, target, topk=1, thresh=None):
    """Calculate accuracy according to the prediction and target.
    Args:
        pred (torch.Tensor): The model prediction, shape (N, num_class)
        target (torch.Tensor): The target of each prediction, shape (N, )
        topk (int | tuple[int], optional): If the predictions in ``topk``
            matches the target, the predictions will be regarded as
            correct ones. Defaults to 1.
        thresh (float, optional): If not None, predictions with scores under
            this threshold are considered incorrect. Default to None.
    Returns:
        float | tuple[float]: If the input ``topk`` is a single integer,
            the function will return a single float as accuracy. If
            ``topk`` is a tuple containing multiple integers, the
            function will return a tuple containing accuracies of
            each ``topk`` number.
    """
    assert isinstance(topk, (int, tuple))
    if isinstance(topk, int):
        topk = (topk, )
        return_single = True
    else:
        return_single = False

    maxk = max(topk)
    if pred.size(0) == 0:
        accu = [pred.new_tensor(0.) for i in range(len(topk))]
        return accu[0] if return_single else accu
    assert pred.ndim == 2 and target.ndim == 1
    assert pred.size(0) == target.size(0)
    assert maxk <= pred.size(1), \
        f'maxk {maxk} exceeds pred dimension {pred.size(1)}'
    pred_value, pred_label = pred.topk(maxk, dim=1)
    pred_label = pred_label.t()  # transpose to shape (maxk, N)
    correct = pred_label.eq(target.view(1, -1).expand_as(pred_label))
    class_acc = list(np.zeros(1203))
    class_num = list(np.zeros(1203))
    for i, j in zip(target.cpu().numpy(), correct[0].cpu().numpy()):
        class_num[int(i)] += 1
        if j:
            class_acc[int(i)] += 1

    # if thresh is not None:
    #     # Only prediction values larger than thresh are counted as correct
    #     correct = correct & (pred_value > thresh).t()
    # res = []
    # for k in topk:
    #     correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)
    #     res.append(correct_k.mul_(100.0 / pred.size(0)))
    return class_acc, class_num
        # [i/(j+np.finfo(np.float32).eps) for i, j in zip(class_acc, class_num)]


class Accuracy(nn.Module):

    def __init__(self, topk=(1, ), thresh=None):
        """Module to calculate the accuracy.
        Args:
            topk (tuple, optional): The criterion used to calculate the
                accuracy. Defaults to (1,).
            thresh (float, optional): If not None, predictions with scores
                under this threshold are considered incorrect. Default to None.
        """
        super().__init__()
        self.topk = topk
        self.thresh = thresh

    def forward(self, pred, target):
        """Forward function to calculate accuracy.
        Args:
            pred (torch.Tensor): Prediction of models.
            target (torch.Tensor): Target for each prediction.
        Returns:
            tuple[float]: The accuracies under different topk criterions.
        """
        return accuracy(pred, target, self.topk, self.thresh)
